{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opennmt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CermakM/OpenNMT-tf/blob/master/jabber-wocky-opennmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5eTzBvR5dxNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# import opennmt as onmt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWpNZw8pkl2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a3041403-4e4a-41c0-ef4a-0e5b505e4694"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CermakM/OpenNMT-tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNMT-tf'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 7453 (delta 167), reused 106 (delta 56), pack-reused 7208\u001b[K\n",
            "Receiving objects: 100% (7453/7453), 11.02 MiB | 13.21 MiB/s, done.\n",
            "Resolving deltas: 100% (5652/5652), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LBFpuLUNk07o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d34958a7-0cfe-4c4b-ee49-69cecd3a2bab"
      },
      "cell_type": "code",
      "source": [
        "cd OpenNMT-tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/OpenNMT-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WEYZBCGVfrVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7E2Lwf1gZHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Main script.\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import six\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from opennmt import __version__\n",
        "from opennmt.models import catalog\n",
        "from opennmt.runner import Runner\n",
        "from opennmt.config import load_model, load_config\n",
        "from opennmt.utils.misc import classes_in_module\n",
        "\n",
        "tf.logging.set_verbosity('DEBUG')\n",
        "\n",
        "# Load and merge run configurations.\n",
        "config = load_config(['reference-config.yaml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Cm9hY6Ug3K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5de172ae-4794-425d-c46f-5c3731501348"
      },
      "cell_type": "code",
      "source": [
        "is_chief = True\n",
        "\n",
        "if is_chief and not tf.gfile.Exists(config[\"model_dir\"]):\n",
        "  tf.logging.info(\"Creating model directory %s\", config[\"model_dir\"])\n",
        "  tf.gfile.MakeDirs(config[\"model_dir\"])\n",
        "\n",
        "model = load_model(\n",
        "    config[\"model_dir\"],\n",
        "    model_name='Transformer',\n",
        "    serialize_model=is_chief)\n",
        "session_config = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=0,\n",
        "    inter_op_parallelism_threads=0,\n",
        "    gpu_options=tf.GPUOptions(\n",
        "        allow_growth=False))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Creating model directory jabber-wocky/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9l5U1KKGjlx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1843
        },
        "outputId": "a878a802-000a-437e-cafa-8dc753200fec"
      },
      "cell_type": "code",
      "source": [
        "args = type('args', (), {})\n",
        "args.run = 'train'\n",
        "args.predictions_file = \"\"\n",
        "args.checkpoint_path  = None\n",
        "\n",
        "runner = Runner(\n",
        "    model,\n",
        "    config,\n",
        "    seed=42,\n",
        "    num_devices=1,\n",
        "    session_config=session_config,\n",
        "    auto_config=False)\n",
        "\n",
        "if args.run == \"train_and_eval\":\n",
        "  runner.train_and_evaluate(checkpoint_path=args.checkpoint_path)\n",
        "elif args.run == \"train\":\n",
        "  runner.train(checkpoint_path=args.checkpoint_path)\n",
        "elif args.run == \"eval\":\n",
        "  runner.evaluate(checkpoint_path=args.checkpoint_path)\n",
        "elif args.run == \"infer\":\n",
        "  if not args.features_file:\n",
        "    parser.error(\"--features_file is required for inference.\")\n",
        "  elif len(args.features_file) == 1:\n",
        "    args.features_file = args.features_file[0]\n",
        "  runner.infer(\n",
        "      args.features_file,\n",
        "      predictions_file=args.predictions_file,\n",
        "      checkpoint_path=args.checkpoint_path,\n",
        "      log_time=args.log_prediction_time)\n",
        "elif args.run == \"export\":\n",
        "  runner.export(\n",
        "      checkpoint_path=args.checkpoint_path,\n",
        "      export_dir_base=args.export_dir_base)\n",
        "elif args.run == \"score\":\n",
        "  if not args.features_file:\n",
        "    parser.error(\"--features_file is required for scoring.\")\n",
        "  if not args.predictions_file:\n",
        "    parser.error(\"--predictions_file is required for scoring.\")\n",
        "  runner.score(\n",
        "      args.features_file,\n",
        "      args.predictions_file,\n",
        "      checkpoint_path=args.checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using parameters: {\n",
            "  \"data\": {\n",
            "    \"eval_features_file\": \"data/src-val.txt\",\n",
            "    \"eval_labels_file\": \"data/tgt-val.txt\",\n",
            "    \"source_words_vocabulary\": \"data/src-vocab.txt\",\n",
            "    \"target_words_vocabulary\": \"data/tgt-vocab.txt\",\n",
            "    \"train_features_file\": \"data/src-train.txt\",\n",
            "    \"train_labels_file\": \"data/tgt-train.txt\"\n",
            "  },\n",
            "  \"eval\": {\n",
            "    \"batch_size\": 30,\n",
            "    \"eval_delay\": 7200,\n",
            "    \"exporters\": \"last\",\n",
            "    \"external_evaluators\": \"BLEU\",\n",
            "    \"num_threads\": 1,\n",
            "    \"prefetch_buffer_size\": 1,\n",
            "    \"save_eval_predictions\": false\n",
            "  },\n",
            "  \"infer\": {\n",
            "    \"batch_size\": 10,\n",
            "    \"n_best\": 1,\n",
            "    \"num_threads\": 1,\n",
            "    \"prefetch_buffer_size\": 1,\n",
            "    \"with_alignments\": null,\n",
            "    \"with_scores\": false\n",
            "  },\n",
            "  \"model_dir\": \"jabber-wocky/\",\n",
            "  \"params\": {\n",
            "    \"average_loss_in_time\": false,\n",
            "    \"beam_width\": 5,\n",
            "    \"clip_gradients\": 5.0,\n",
            "    \"decay_rate\": 0.7,\n",
            "    \"decay_step_duration\": 1,\n",
            "    \"decay_steps\": 10000,\n",
            "    \"decay_type\": \"exponential_decay\",\n",
            "    \"guided_alignment_type\": null,\n",
            "    \"guided_alignment_weight\": 1,\n",
            "    \"label_smoothing\": 0.1,\n",
            "    \"learning_rate\": 0.001,\n",
            "    \"length_penalty\": 0.2,\n",
            "    \"loss_scale\": \"backoff\",\n",
            "    \"loss_scale_params\": {\n",
            "      \"scale_min\": 1.0,\n",
            "      \"step_factor\": 2.0\n",
            "    },\n",
            "    \"maximum_iterations\": 200,\n",
            "    \"minimum_decoding_length\": 0,\n",
            "    \"minimum_learning_rate\": 0.0001,\n",
            "    \"optimizer\": \"AdamOptimizer\",\n",
            "    \"optimizer_params\": {\n",
            "      \"beta1\": 0.8,\n",
            "      \"beta2\": 0.998\n",
            "    },\n",
            "    \"param_init\": 0.1,\n",
            "    \"regularization\": {\n",
            "      \"scale\": \"1e-4\",\n",
            "      \"type\": \"l2\"\n",
            "    },\n",
            "    \"replace_unknown_target\": false,\n",
            "    \"staircase\": true,\n",
            "    \"start_decay_steps\": 50000\n",
            "  },\n",
            "  \"score\": {\n",
            "    \"batch_size\": 64,\n",
            "    \"num_threads\": 1,\n",
            "    \"prefetch_buffer_size\": 1,\n",
            "    \"with_alignments\": null,\n",
            "    \"with_token_level\": false\n",
            "  },\n",
            "  \"train\": {\n",
            "    \"average_last_checkpoints\": 8,\n",
            "    \"batch_size\": 64,\n",
            "    \"batch_type\": \"examples\",\n",
            "    \"bucket_width\": 5,\n",
            "    \"keep_checkpoint_max\": 3,\n",
            "    \"maximum_features_length\": 70,\n",
            "    \"maximum_labels_length\": 70,\n",
            "    \"num_threads\": 4,\n",
            "    \"prefetch_buffer_size\": null,\n",
            "    \"sample_buffer_size\": 500000,\n",
            "    \"save_checkpoints_steps\": 500,\n",
            "    \"save_summary_steps\": 100,\n",
            "    \"single_pass\": false,\n",
            "    \"train_steps\": 10000\n",
            "  }\n",
            "}\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'jabber-wocky/', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    layout_optimizer: OFF\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a56a3bf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Number of trainable parameters: 93655532\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into jabber-wocky/model.ckpt.\n",
            "INFO:tensorflow:loss = 166.79327, step = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fu3SRe02lxmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}